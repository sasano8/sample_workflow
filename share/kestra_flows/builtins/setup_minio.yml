id: setup_minio
namespace: tutorial.builtin

tasks:
  - id: cleanup_default_bucket
    type: io.kestra.plugin.scripts.shell.Commands
    runner: DOCKER
    docker:
      image: minio/mc
      entryPoint:
        - ""
      networkMode: "internal"
    env:
      S3_ALIAS: "myminio"
      AWS_S3_LOCATION: "{{ kv('AWS_S3_LOCATION') }}"
      AWS_ACCESS_KEY_ID: "{{ kv('AWS_ACCESS_KEY_ID') }}"
      AWS_SECRET_ACCESS_KEY: "{{ kv('AWS_SECRET_ACCESS_KEY') }}"
      AWS_REGION: "{{ kv('AWS_REGION') }}"
      AWS_BUCKET: "{{ kv('AWS_BUCKET') }}"
    commands:
      # - "echo $AWS_S3_LOCATION $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY $AWS_REGION"
      - "/usr/bin/mc alias set $S3_ALIAS $AWS_S3_LOCATION $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY"
      - "/usr/bin/mc ls $S3_ALIAS"
      - "/usr/bin/mc rb --force $S3_ALIAS/$AWS_BUCKET"  # バケット削除
      - "/usr/bin/mc mb $S3_ALIAS/$AWS_BUCKET"  # バケット作成
      - "/usr/bin/mc anonymous set public $S3_ALIAS/$AWS_BUCKET"  # public にする

  # TODO: warehouse を指定していないのに、なぜ s3://warehouse にリクエストがいくのか？
  - id: custom_image
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: docker.io/python:3.10.16-slim
      networkMode: "internal"
    env:
      AWS_ACCESS_KEY_ID: "{{ kv('AWS_ACCESS_KEY_ID') }}"
      AWS_SECRET_ACCESS_KEY: "{{ kv('AWS_SECRET_ACCESS_KEY') }}"
      AWS_REGION: "{{ kv('AWS_REGION') }}"
      ICEBERG_URL: "{{ kv('ICEBERG_URL') }}"
      ICEBERG_REF: "{{ kv('ICEBERG_REF') }}"
      # AWS_BUCKET: "warehouse"
    beforeCommands:
      # - apt-get update && apt-get install -y curl
      # - curl http://rest-iceberg:8181
      # - curl $AWS_S3_LOCATION
      - echo $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY $AWS_REGION $AWS_BUCKET
      - pip install pyiceberg[s3fs] pyarrow pandas
      # - sleep 1000
    script: |
      from pyiceberg.catalog import load_catalog
      import pandas as pd
      import pyarrow as pa
      from os import environ

      AWS_ACCESS_KEY_ID = environ.get("AWS_ACCESS_KEY_ID")
      AWS_SECRET_ACCESS_KEY = environ.get("AWS_SECRET_ACCESS_KEY")
      AWS_REGION = environ.get("AWS_REGION")
      # AWS_BUCKET = environ.get("AWS_BUCKET")
      ICEBERG_URL = environ.get("ICEBERG_URL")
      ICEBERG_REF = environ.get("ICEBERG_REF")

      # 構成例１
      # rest + S3 : rest にカタログメタデータと S3のバケットに１つのカタログ（テーブル群）を管理する。S3 だけを削除したりすると、rest 側のゴミと不一致になりバグが生じる
      # 例えば、rest 側には s3://warehouse にオープンテーブルフォーマットが置かれていると管理されているものの、実際に取りに行くと存在しない

      # 構成例２
      # sqlite + S3FS : sqlite にカタログメタデータを置き、かつ、同じ場所にオープンテーブルフォーマットも管理する
      # S3FS で S3 をローカルファイルシステムにマウントしておくことでS3と同期が図れるものの、排他処理が効かず、チームで作業した場合は環境が壊れてしまう
      # 一人で使う場合には構成が簡素で使い勝手がよい

      catalog_name = "tutorial"
      conf_catalog = {
        "uri": ICEBERG_URL,
        "ref": ICEBERG_REF
      }

      # conf_catalog = {
      #     "uri": "http://rest-iceberg:8181",
      #     "py-io-impl": "pyiceberg.io.pyarrow.PyArrowFileIO",
      #     "s3.endpoint": "http://minio:9000",
      #     "s3.access-key-id": environ.get("AWS_ACCESS_KEY_ID"),
      #     "s3.secret-access-key": environ.get("AWS_SECRET_ACCESS_KEY"),
      #     "s3.region": environ.get("AWS_REGION")
      # }

      catalog = load_catalog(
          catalog_name,
          **conf_catalog
      )

      catalog.create_namespace_if_not_exists("default")

      TABLE_NAME = "default.taxi_dataset"

      # pa.Table.from_pandas: pandas を使う場合
      pa_table = pa.Table.from_pydict({
        "id": [1, 2, 3],
        "name": ["Alice", "Bob", "Charlie"],
        "age": [25, 30, 28],
        "salary": [50000.0, 60000.0, 55000.0]
      })

      if not catalog.table_exists(TABLE_NAME):
        with catalog.create_table_transaction(
            identifier=TABLE_NAME,
            schema=pa_table.schema,
            # location="s3://pyiceberg",
            # partition_spec=partition_spec,
            # sort_order=sort_order,
        ) as txn:
            # with txn.update_schema() as update_schema:
            #     update_schema.add_column(path="new_column", field_type=StringType())

            # with txn.update_spec() as update_spec:
            #     update_spec.add_identity("symbol")

            # txn.set_properties(test_a="test_aa", test_b="test_b", test_c="test_c")

            txn.append(pa_table)

      loaded_table = catalog.load_table(TABLE_NAME)
      print(loaded_table.scan().to_arrow())

      # UnityCatalog の接続方法
      # rest_catalog = load_catalog(
      #   "databricks",
      #   **{
      #       "type": "rest",
      #       "warehouse": "unity",
      #       "uri": "http://127.0.0.1:8080/api/2.1/unity-catalog/iceberg",
      #   }
      # )

