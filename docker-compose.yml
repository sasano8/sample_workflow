---
version: "3.8"

x-v01: &MINIO_ROOT_USER "${MINIO_ROOT_USER:-admin}"
x-v02: &MINIO_ROOT_PASSWORD "${MINIO_ROOT_PASSWORD:-password}"

services:
  minio:
    image: minio/minio
    environment:
      MINIO_ROOT_USER: *MINIO_ROOT_USER
      MINIO_ROOT_PASSWORD: *MINIO_ROOT_PASSWORD
      MINIO_DOMAIN: minio
    networks:
      internal:
        aliases:
          - warehouse.minio
    ports:
      - 9001:9001
      - 9000:9000
    command: ["server", "/data", "--console-address", ":9001"]

  # https://projectnessie.org/guides/spark-s3/#setting-up-spark-session-for-minio
  nessie:
    image: ghcr.io/projectnessie/nessie
    ports:
      - "19120:19120"
      - "19110:9000"  # なんかUIが有効になるみたいだが映らない
    environment:
      # https://www.dremio.com/blog/intro-to-pyiceberg/
      - nessie.server.authentication.enabled=false
      - nessie.version.store.type=IN_MEMORY
      - nessie.server.default-branch=main
      - nessie.catalog.service.s3.default-options.access-key=urn:nessie-secret:quarkus:nessie.catalog.secrets.access-key
      - nessie.catalog.service.s3.default-options.path-style-access=true
      - nessie.catalog.default-warehouse=warehouse
      - nessie.catalog.warehouses.warehouse.location=s3://warehouse/
      - nessie.catalog.service.s3.default-options.endpoint=http://minio:9000/
      - nessie.catalog.secrets.access-key.name=admin
      - nessie.catalog.secrets.access-key.secret=password
      - nessie.catalog.service.s3.default-options.region=us-east-1
    networks:
      internal:

  kestra:
    image: kestra/kestra:latest
    networks:
      internal:
    container_name: myflow
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      - ".configs/kestra.yaml:/etc/config/application.yaml"
      - ".volume/kestra:/tmp"
      - "./share:/mnt/share/builtins"
      - "/mnt/share:/mnt/share/host"
    ports:
      - 8080:8080
    user: root:980  # 980 -> sharedgroup
    command:
      - server
      - local  # 開発用　データベースなどが内包されている
      - "--flow-path"  # 起動時に読み込むフロー
      - "/mnt/share/builtins/kestra_flows"

  mlflow:
    networks:
      internal:
    build:
      context: .
      dockerfile: ./dockerfiles/mlflow.Dockerfile
    expose:
      - "5000"
    ports:
      - "5000:5000"
    environment:
      MLFLOW_BACKEND_STORE_URI: "sqlite:///mlrunsdb.db"  # Parameters, Metrics の管理
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000  # 非構造データの管理
      AWS_ACCESS_KEY_ID: "admin"
      AWS_SECRET_ACCESS_KEY: "password"
      AWS_DEFAULT_REGION: "us-east-1"
      MLFLOW_ARTIFACT_ROOT: "s3://mlflow/"
      DEST_ARTIFACT: "s3://mlflow/artifacts"
      # export MLFLOW_S3_UPLOAD_EXTRA_ARGS='{"ServerSideEncryption": "aws:kms", "SSEKMSKeyId": "1234"}'
    # トラッキングサーバ： トラッキングの制御と結果のUI表示
    # バックエンド： Parameters, Metrics の管理
    # Artifact： 非構造データの管理
    # レジストリサーバ： モデルとバージョン情報を管理
    command: 'mlflow server --host 0.0.0.0 --serve-artifacts --artifacts-destination "$DEST_ARTIFACT"'

  open-webui:
    # image: ghcr.io/open-webui/open-webui:main
    image: ghcr.io/open-webui/open-webui:cuda
    runtime: nvidia
    environment:
      WEBUI_AUTH: false
      ENABLE_OLLAMA_API: true
      # ENABLE_SIGNUP: false
      # ENABLE_LOGIN_FORM: false
      USE_OLLAMA_DOCKER: false
      OLLAMA_BASE_URL: http://host.docker.internal:11434
      # USE_OLLAMA_DOCKER: true
      HF_HUB_OFFLINE: 0
      USE_CUDA_DOCKER: true
    ports:
      - "3090:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ".volume/open-webui:/app/backend/data"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]


  rest-iceberg:
    image: apache/iceberg-rest-fixture
    # container_name: iceberg-rest
    networks:
      internal:
    ports:
      - 8181:8181
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - CATALOG_WAREHOUSE=s3://warehouse/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000

  spark-iceberg:
    image: tabulario/spark-iceberg
    # container_name: spark-iceberg
    build: spark/
    networks:
      internal:
    depends_on:
      - rest-iceberg
      - minio
    # volumes:
    #   - .volume/warehouse:/home/iceberg/warehouse
    #   - .volume/notebooks:/home/iceberg/notebooks/notebooks
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      # - ICEBERG_CATALOG_REST=rest-iceberg:8181  # 追加してみたが動くのか分からない
    ports:
      - 9999:8888
      - 8980:8080
      - 10000:10000
      - 10001:10001
  # spark を起動するには
  # /opt/spark/bin/spark-shell
  # spark.conf.getAll.foreach(println)  # 構成を確認する
  # cat ./conf/spark-defaults.conf

  unitycatalog:
    # 現状 s3 には接続できないみたいだ
    networks:
        internal:
    build:
      context: .
      dockerfile: ./dockerfiles/UnityCatalog.Dockerfile
    ports:
      - "8888:8080"
      - "3000:3000"
    environment:
      JAVA_HOME: /usr/local/openjdk-17
    # command: ["bin/start-uc-server"]
  # unitycatalog-ui:





  # 分散フレームワーク
  # ray:
  #   image: rayproject/ray
  #   environment:
  #     - RAY_GCS_RPC_SERVER_PORT=10001
  #   ports:
  #     - "6379:6379"     # クラスター管理ポート
  #     - "8265:8265"     # Ray ダッシュボード
  #     - "10002:10001"   # gRPC ベースのクラスター通信ポート  # 範囲指定できるっぽい（min_worker_port, max_worker_port）
  #   command: >
  #     ray start --head --port=6379 --dashboard-host=0.0.0.0
  #   networks:
  #     - ray_network

  # triton:
  #   image: nvcr.io/nvidia/tritonserver:latest
  #   # 先にdocker login nvcr.io しておく必要がある。しかし、ログインできず挫折。
  #   volumes:
  #   - ".volume/toriton:/models"
  #   command: "tritonserver --model-repository=/models"
# mlflow deployments create -t triton --flavor triton --name model_name -m models:/model_name/1
# pythonを使う場合
# from mlflow.deployments import get_deploy_client
# client = get_deploy_client('triton')
# client.create_deployment("model_name", "models:/model_name/1", flavor="triton")


  # portainer:
  #   image: portainer/portainer-ce:2.21.5
  #   container_name: portainer
  #   volumes:
  #     - "/var/run/docker.sock:/var/run/docker.sock"
  #     - ".volume/portainer_data:/data"
  #   ports:
  #     - "8000:8000"
  #     - "9443:9443"
  #   # restart: always

  # docker-registry:
  #   image: registry:2
  #   ports:
  #     - "5000:5000"
  #   environment:
  #     REGISTRY_STORAGE: s3
  #     REGISTRY_STORAGE_S3_REGION: us-east-1
  #     REGISTRY_STORAGE_S3_BUCKET: container_registry
  #     REGISTRY_STORAGE_S3_ACCESSKEY: hummockadmin
  #     REGISTRY_STORAGE_S3_SECRETKEY: hummockadmin

networks:
  internal:
    name: internal
  # ray_network:
  #   driver: bridge

# * ParadeDB: postgres に elasticsearch を盛り込む拡張機能
# * pg_analytics: postgres13以降 に iceberg や deltalake の連携機能を追加する

# secrets:
#   my_secret:
#     file: ./.env
