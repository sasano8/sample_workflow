---
services:
  kestra:
    image: kestra/kestra:latest
    networks:
      internal:
    container_name: myflow
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      - ".configs/kestra.yaml:/etc/config/application.yaml"
      - ".volume/kestra:/tmp"
      - "./share:/mnt/share"
    ports:
      - 8080:8080
    user: root:root
    command:
      - server
      - local  # 開発用　データベースなどが内包されている
      - "--flow-path"
      - "/mnt/share/kestra_flows"
  # portainer:
  #   image: portainer/portainer-ce:2.21.5
  #   container_name: portainer
  #   volumes:
  #     - "/var/run/docker.sock:/var/run/docker.sock"
  #     - ".volume/portainer_data:/data"
  #   ports:
  #     - "8000:8000"
  #     - "9443:9443"
  #   # restart: always
  minio:
    image: minio/minio
    # container_name: minio
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
    networks:
      internal:
        aliases:
          - warehouse.minio
    ports:
      - 9001:9001
      - 9000:9000
    command: ["server", "/data", "--console-address", ":9001"]

  rest-iceberg:
    image: apache/iceberg-rest-fixture
    # container_name: iceberg-rest
    networks:
      internal:
    ports:
      - 8181:8181
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - CATALOG_WAREHOUSE=s3://warehouse/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000

  spark-iceberg:
    image: tabulario/spark-iceberg
    # container_name: spark-iceberg
    build: spark/
    networks:
      internal:
    depends_on:
      - rest-iceberg
      - minio
    # volumes:
    #   - .volume/warehouse:/home/iceberg/warehouse
    #   - .volume/notebooks:/home/iceberg/notebooks/notebooks
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      # - ICEBERG_CATALOG_REST=rest-iceberg:8181  # 追加してみたが動くのか分からない
    ports:
      - 9999:8888
      - 8980:8080
      - 10000:10000
      - 10001:10001
  # spark を起動するには
  # /opt/spark/bin/spark-shell
  # spark.conf.getAll.foreach(println)  # 構成を確認する
  # cat ./conf/spark-defaults.conf

  unitycatalog:
    # 現状 s3 には接続できないみたいだ
    networks:
        internal:
    build:
      context: .
      dockerfile: ./dockerfiles/UnityCatalog.Dockerfile
    ports:
      - "8888:8080"
      - "3000:3000"
    environment:
      JAVA_HOME: /usr/local/openjdk-17
    # command: ["bin/start-uc-server"]
  # unitycatalog-ui:

networks:
  internal:
    name: internal


# * ParadeDB: postgres に elasticsearch を盛り込む拡張機能
# * pg_analytics: postgres13以降 に iceberg や deltalake の連携機能を追加する
